name: CVC5 RQ2 Measurement - Variant1

on:
  workflow_dispatch:
    inputs:
      debug_commit_hash:
        description: 'Debug: Specific commit hash to measure. If provided, only this commit will be measured.'
        required: false
        type: string
      dry_run:
        description: 'Dry run: Skip S3 uploads (default: false)'
        required: false
        type: boolean
        default: false

jobs:
  # ============================================================
  # PHASE 1: Generate commit matrix from available recipes
  # ============================================================
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      commit_matrix: ${{ steps.generate-matrix.outputs.commit_matrix }}
      total_commits: ${{ steps.generate-matrix.outputs.total_commits }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: pip install boto3
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Generate commit matrix from recipes
        id: generate-matrix
        env:
          AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          if [ -n "${{ inputs.debug_commit_hash }}" ]; then
            echo "ðŸ” Debug mode: Using specific commit ${{ inputs.debug_commit_hash }}"
            DEBUG_COMMIT="${{ inputs.debug_commit_hash }}"
            COMMIT_MATRIX=$(python3 -c "import json; print(json.dumps({'include': [{'commit': '$DEBUG_COMMIT'}]}, separators=(',', ':')))")
            TOTAL_COMMITS=1
          else
            # List commits that have variant1 recipes
            prefix="evaluation/rq2/cvc5/fuzzing-recipes/variant1/"
            commits=$(aws s3 ls s3://${{ secrets.AWS_S3_BUCKET }}/$prefix --recursive | \
              grep "recipes-" | \
              sed 's/.*recipes-\(.*\)\.jsonl\.gz/\1/' | \
              sort -u)
            
            commit_count=$(echo "$commits" | grep -c . || echo 0)
            echo "âœ… Found $commit_count commits with variant1 recipes"
            
            # Generate matrix
            echo "[]" > /tmp/matrix_entries.json
            for commit in $commits; do
              jq --arg commit "$commit" '. + [{"commit": $commit}]' /tmp/matrix_entries.json > /tmp/matrix_entries_new.json
              mv /tmp/matrix_entries_new.json /tmp/matrix_entries.json
            done
            
            COMMIT_MATRIX=$(jq -c '{include: .}' /tmp/matrix_entries.json)
            TOTAL_COMMITS=$commit_count
          fi
          
          echo "commit_matrix=$COMMIT_MATRIX" >> $GITHUB_OUTPUT
          echo "total_commits=$TOTAL_COMMITS" >> $GITHUB_OUTPUT

  # ============================================================
  # PHASE 2: Prepare measurement - split recipes into 4 jobs per commit
  # ============================================================
  prepare-measurement:
    needs: generate-matrix
    if: needs.generate-matrix.outputs.total_commits != '' && needs.generate-matrix.outputs.total_commits != '0'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-matrix.outputs.commit_matrix) }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Download recipes from S3
        run: |
          COMMIT_HASH="${{ matrix.commit }}"
          S3_KEY="evaluation/rq2/cvc5/fuzzing-recipes/variant1/recipes-${COMMIT_HASH}.jsonl.gz"
          
          aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/$S3_KEY recipes.jsonl.gz
          gunzip recipes.jsonl.gz
          
          RECIPE_COUNT=$(wc -l < recipes.jsonl)
          echo "âœ… Downloaded $RECIPE_COUNT recipes for variant1 measurement"
      
      - name: Split recipes into 4 jobs
        run: |
          python3 scripts/rq2/split_recipes_for_measurement.py \
            recipes.jsonl \
            --num-jobs 4 \
            --output measurement_matrix.json
          
          echo "=== Measurement Matrix ==="
          cat measurement_matrix.json | python3 -m json.tool
          
          # Create combined matrix with commit
          jq -c --arg commit "${{ matrix.commit }}" '{
            "include": (.matrix.include | map({
              "commit": $commit,
              "job_id": .job_id,
              "start_idx": .start_idx,
              "end_idx": .end_idx,
              "recipe_count": .recipe_count
            }))
          }' measurement_matrix.json > combined_matrix.json
          
          echo "=== Combined Matrix ==="
          cat combined_matrix.json | python3 -m json.tool
      
      - name: Upload combined matrix
        uses: actions/upload-artifact@v4
        with:
          name: variant1-measurement-matrix-${{ matrix.commit }}
          path: combined_matrix.json
          if-no-files-found: error

  # ============================================================
  # PHASE 3: Collect all matrices into one
  # ============================================================
  collect-matrices:
    needs: [generate-matrix, prepare-measurement]
    if: always() && needs.prepare-measurement.result == 'success'
    runs-on: ubuntu-latest
    outputs:
      measurement_matrix: ${{ steps.merge-matrices.outputs.measurement_matrix }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      
      - name: Download all combined matrices
        uses: actions/download-artifact@v4
        with:
          path: matrices
          pattern: variant1-measurement-matrix-*
          merge-multiple: false
      
      - name: Merge all matrices
        id: merge-matrices
        run: |
          # Use Python script for reliable matrix merging
          TOTAL_JOBS=$(python3 scripts/merge_fuzzing_matrices.py \
            measurement_matrix.json \
            "matrices/variant1-measurement-matrix-*/combined_matrix.json" \
            --minimal-output measurement_matrix_minimal.json)
          
          MINIMAL_MATRIX=$(cat measurement_matrix_minimal.json)
          echo "measurement_matrix=$MINIMAL_MATRIX" >> $GITHUB_OUTPUT
          echo "total_jobs=$TOTAL_JOBS" >> $GITHUB_OUTPUT
          echo "âœ… Merged $TOTAL_JOBS measurement jobs"
      
      - name: Upload merged matrix
        uses: actions/upload-artifact@v4
        with:
          name: variant1-measurement-matrix-full
          path: measurement_matrix.json
          retention-days: 1

  # ============================================================
  # PHASE 4: Run measurement jobs (4 per commit, in parallel)
  # ============================================================
  measurement-jobs:
    needs: [generate-matrix, prepare-measurement, collect-matrices]
    if: needs.collect-matrices.outputs.measurement_matrix != '' && needs.collect-matrices.outputs.measurement_matrix != '{"include":[]}'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.collect-matrices.outputs.measurement_matrix) }}
    timeout-minutes: 360
    
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      
      - name: Download full matrix data
        uses: actions/download-artifact@v4
        with:
          name: variant1-measurement-matrix-full
          path: .
      
      - name: Extract job parameters
        id: job-params
        run: |
          # Extract parameters for this job from full matrix
          JOB_DATA=$(jq -r ".include[] | select(.commit == \"${{ matrix.commit }}\" and .job_id == ${{ matrix.job_id }})" measurement_matrix.json)
          START_IDX=$(echo "$JOB_DATA" | jq -r '.start_idx')
          END_IDX=$(echo "$JOB_DATA" | jq -r '.end_idx')
          RECIPE_COUNT=$(echo "$JOB_DATA" | jq -r '.recipe_count')
          
          echo "start_idx=$START_IDX" >> $GITHUB_OUTPUT
          echo "end_idx=$END_IDX" >> $GITHUB_OUTPUT
          echo "recipe_count=$RECIPE_COUNT" >> $GITHUB_OUTPUT
          
          echo "ðŸ“Š Job ${{ matrix.job_id }}: recipes $START_IDX to $END_IDX ($RECIPE_COUNT recipes)"
      
      - name: Install GCC 14 (for gcov)
        run: |
          sudo apt-get update
          # gcov-14 is included with gcc-14 (not a separate package)
          sudo apt-get install -y gcc-14 g++-14
          sudo update-alternatives --install /usr/bin/gcov gcov /usr/bin/gcov-14 60
          pip install fastcov
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          pip install antlr4-python3-runtime==4.9.2
          pip install z3-solver
          pip install psutil
          git clone https://github.com/testsmt/yinyang.git
          cd yinyang && pip install -e . && cd ..
      
      - name: Clone CVC5 repository
        run: |
          git clone https://github.com/cvc5/cvc5.git cvc5
      
      - name: Checkout commit
        working-directory: cvc5
        run: |
          git fetch origin
          git checkout ${{ matrix.commit }}
          echo "Checked out commit: $(git rev-parse HEAD)"
      
      - name: Get full commit hash
        id: get-commit
        working-directory: cvc5
        run: |
          FULL_HASH=$(git rev-parse HEAD)
          echo "commit_hash=$FULL_HASH" >> $GITHUB_OUTPUT
      
      - name: Clean up git repositories
        run: rm -rf cvc5/.git yinyang/.git || true
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Download recipes from S3
        run: |
          COMMIT_HASH="${{ steps.get-commit.outputs.commit_hash }}"
          S3_KEY="evaluation/rq2/cvc5/fuzzing-recipes/variant1/recipes-${COMMIT_HASH}.jsonl.gz"
          
          aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/$S3_KEY recipes.jsonl.gz
          gunzip recipes.jsonl.gz
          
          RECIPE_COUNT=$(wc -l < recipes.jsonl)
          echo "âœ… Downloaded $RECIPE_COUNT total recipes"
          
          # Show sample
          echo ""
          echo "=== First 5 recipes (sample) ==="
          head -5 recipes.jsonl | python3 -m json.tool --no-ensure-ascii 2>/dev/null || head -5 recipes.jsonl
      
      - name: Download gcov binary from S3
        run: |
          COMMIT_HASH="${{ steps.get-commit.outputs.commit_hash }}"
          S3_KEY="evaluation/rq2/cvc5/builds/coverage/${COMMIT_HASH}.tar.gz"
          
          mkdir -p artifacts
          aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/$S3_KEY artifacts/artifacts.tar.gz
          echo "âœ… Downloaded gcov binary for $COMMIT_HASH"
      
      - name: Extract gcov binary
        run: |
          ./scripts/cvc5/extract_build_artifacts.sh artifacts/artifacts.tar.gz cvc5/build true
          echo "âœ… Extracted build artifacts"
          
          # Verify gcno files exist
          GCNO_COUNT=$(find cvc5/build -name "*.gcno" | wc -l)
          echo "Found $GCNO_COUNT .gcno files"
      
      - name: Download changed functions from S3
        run: |
          COMMIT_HASH="${{ steps.get-commit.outputs.commit_hash }}"
          S3_KEY="evaluation/rq2/cvc5/changed-functions/changed_functions-${COMMIT_HASH}.json.gz"
          
          aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/$S3_KEY changed_functions.json.gz
          gunzip changed_functions.json.gz
          
          FUNC_COUNT=$(jq '.changed_functions | length' changed_functions.json 2>/dev/null || echo "unknown")
          echo "âœ… Downloaded changed functions: $FUNC_COUNT functions"
          
          # Show changed functions content
          echo ""
          echo "=== Changed Functions ==="
          cat changed_functions.json | python3 -m json.tool
      
      - name: Verify solver binary
        run: |
          cvc5/build/bin/cvc5 --version
      
      - name: Run recipe replay for measurement
        run: |
          START_IDX="${{ steps.job-params.outputs.start_idx }}"
          END_IDX="${{ steps.job-params.outputs.end_idx }}"
          
          echo "=== Starting recipe replay for job ${{ matrix.job_id }} ==="
          echo "    Slice: [$START_IDX:$END_IDX]"
          
          python3 scripts/rq2/replay_recipes.py \
            recipes.jsonl \
            --solver cvc5/build/bin/cvc5 \
            --build-dir cvc5/build \
            --changed-functions changed_functions.json \
            --output measurement_result_${{ matrix.commit }}_job${{ matrix.job_id }}.json \
            --gcov gcov-14 \
            --timeout 120 \
            --num-workers 1 \
            --batch-size 100 \
            --start-idx $START_IDX \
            --end-idx $END_IDX
          
          echo "=== Measurement complete for job ${{ matrix.job_id }} ==="
      
      - name: Show job measurement results
        if: always()
        run: |
          RESULT_FILE="measurement_result_${{ matrix.commit }}_job${{ matrix.job_id }}.json"
          if [ -f "$RESULT_FILE" ]; then
            echo "=== MEASUREMENT RESULTS (Job ${{ matrix.job_id }}) ==="
            cat "$RESULT_FILE" | python3 -m json.tool
          else
            echo "âš ï¸ Measurement results file not found"
          fi
      
      - name: Upload job result artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: variant1-measurement-result-${{ matrix.commit }}-job${{ matrix.job_id }}
          path: measurement_result_${{ matrix.commit }}_job${{ matrix.job_id }}.json
          if-no-files-found: ignore

  # ============================================================
  # PHASE 5: Merge results and upload to S3
  # ============================================================
  merge-and-upload-results:
    needs: [generate-matrix, prepare-measurement, measurement-jobs]
    if: always() && needs.prepare-measurement.result == 'success'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-matrix.outputs.commit_matrix) }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Download job result artifacts
        uses: actions/download-artifact@v4
        with:
          path: results-artifacts
          pattern: variant1-measurement-result-${{ matrix.commit }}-job*
          merge-multiple: false
      
      - name: List downloaded artifacts
        run: |
          echo "=== Downloaded artifacts ==="
          find results-artifacts -type f -name "*.json" | sort
      
      - name: Merge job results
        run: |
          RESULT_FILES=$(find results-artifacts -name "measurement_result_*.json" | sort)
          FILE_COUNT=$(echo "$RESULT_FILES" | grep -c . || echo 0)
          
          echo "Found $FILE_COUNT result files to merge"
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "âš ï¸ No result files found"
            exit 0
          fi
          
          python3 scripts/rq2/merge_measurement_results.py \
            merged_measurement_${{ matrix.commit }}.json \
            $RESULT_FILES
          
          echo ""
          echo "=== MERGED MEASUREMENT RESULTS ==="
          cat merged_measurement_${{ matrix.commit }}.json | python3 -m json.tool
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Upload merged results to S3
        if: always() && !inputs.dry_run
        run: |
          COMMIT_HASH="${{ matrix.commit }}"
          S3_KEY="evaluation/rq2/cvc5/measurement-results/variant1/measurement-${COMMIT_HASH}.json.gz"
          
          if [ ! -f "merged_measurement_${{ matrix.commit }}.json" ]; then
            echo "âš ï¸ Merged measurement results file not found"
            exit 0
          fi
          
          gzip -c "merged_measurement_${{ matrix.commit }}.json" > measurement_${COMMIT_HASH}.json.gz
          
          aws s3api put-object \
            --bucket ${{ secrets.AWS_S3_BUCKET }} \
            --key "$S3_KEY" \
            --body measurement_${COMMIT_HASH}.json.gz
          
          echo "âœ… Uploaded variant1 measurement results to S3: $S3_KEY"
