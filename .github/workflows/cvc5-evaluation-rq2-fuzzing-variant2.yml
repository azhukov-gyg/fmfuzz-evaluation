name: CVC5 RQ2 Fuzzing - Variant2 (Coverage-Guided)

on:
  workflow_dispatch:
    inputs:
      fuzzing_duration_minutes:
        description: 'Fuzzing duration in minutes (default: 60)'
        required: false
        type: number
        default: 60
      debug_commit_hash:
        description: 'Debug: Specific commit hash to test. If provided, only this commit will be fuzzed.'
        required: false
        type: string
      dry_run:
        description: 'Dry run: Skip S3 uploads (default: false)'
        required: false
        type: boolean
        default: false

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      commit_matrix: ${{ steps.generate-matrix.outputs.commit_matrix }}
      total_commits: ${{ steps.generate-matrix.outputs.total_commits }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: pip install boto3
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Generate commit matrix
        id: generate-matrix
        env:
          AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          if [ -n "${{ inputs.debug_commit_hash }}" ]; then
            echo "ðŸ” Debug mode: Using specific commit ${{ inputs.debug_commit_hash }}"
            DEBUG_COMMIT="${{ inputs.debug_commit_hash }}"
            COMMIT_MATRIX=$(python3 -c "import json; print(json.dumps({'include': [{'commit': '$DEBUG_COMMIT'}]}, separators=(',', ':')))")
            TOTAL_COMMITS=1
          else
            RESULT=$(python3 scripts/rq2/generate_fuzzing_matrix.py cvc5)
            COMMIT_MATRIX=$(echo "$RESULT" | python3 -c "import sys, json; data=json.load(sys.stdin); print(json.dumps({'include': data['include']}, separators=(',', ':')))")
            TOTAL_COMMITS=$(echo "$RESULT" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data['total_commits'])")
          fi
          
          echo "commit_matrix=$COMMIT_MATRIX" >> $GITHUB_OUTPUT
          echo "total_commits=$TOTAL_COMMITS" >> $GITHUB_OUTPUT
          echo "âœ… Generated matrix: $TOTAL_COMMITS commits"

  prepare-commit-fuzzer:
    needs: generate-matrix
    if: needs.generate-matrix.outputs.total_commits != '' && needs.generate-matrix.outputs.total_commits != '0'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-matrix.outputs.commit_matrix) }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      
      - name: Install LLVM/Clang 17
        uses: KyleMayes/install-llvm-action@v2
        with:
          version: '17'

      - name: Add LLVM to PATH
        run: echo "${{ env.LLVM_PATH }}/bin" >> $GITHUB_PATH

      - name: Export LIBCLANG_PATH
        run: echo "LIBCLANG_PATH=${{ env.LLVM_PATH }}/lib" >> $GITHUB_ENV

      - name: Install system packages
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            build-essential libc6-dev gcc g++ binutils \
            libstdc++-14-dev libc++-dev libc++abi-dev zlib1g zlib1g-dev

      - name: Install Python dependencies
        run: pip install gitpython unidiff "libclang==17.0.6"

      - name: Clone CVC5 repository
        run: |
          if [ ! -d "cvc5" ]; then
            git clone https://github.com/cvc5/cvc5.git cvc5
          fi

      - name: Checkout specific commit
        working-directory: cvc5
        run: |
          COMMIT_HASH="${{ matrix.commit }}"
          git fetch origin
          git checkout $COMMIT_HASH
          echo "Checked out commit: $(git rev-parse HEAD)"

      - name: Get CVC5 commit hash
        id: get-commit
        working-directory: cvc5
        run: |
          COMMIT_HASH=$(git rev-parse HEAD)
          echo "commit_hash=$COMMIT_HASH" >> $GITHUB_OUTPUT
          echo "CVC5 commit hash: $COMMIT_HASH"

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Download coverage mapping from S3
        run: |
          COMMIT_HASH="${{ steps.get-commit.outputs.commit_hash }}"
          S3_KEY="evaluation/rq2/cvc5/coverage-mappings/variant1/coverage_mapping-${COMMIT_HASH}.json.gz"
          aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/$S3_KEY coverage_mapping.json.gz
          gunzip coverage_mapping.json.gz
          echo "âœ… Downloaded coverage mapping"

      - name: Download coverage binary from S3 (for compile_commands.json)
        run: |
          COMMIT_HASH="${{ steps.get-commit.outputs.commit_hash }}"
          S3_KEY="evaluation/rq2/cvc5/builds/coverage/${COMMIT_HASH}.tar.gz"
          
          mkdir -p artifacts
          aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/$S3_KEY artifacts/artifacts.tar.gz
          echo "âœ… Downloaded coverage binary for $COMMIT_HASH"

      - name: Extract coverage binary
        run: |
          mkdir -p cvc5/build
          ./scripts/cvc5/extract_build_artifacts.sh artifacts/artifacts.tar.gz cvc5/build true
          echo "âœ… Extracted build artifacts (includes compile_commands.json)"

      - name: Run prepare commit fuzzer
        id: prepare
        working-directory: cvc5
        env:
          SKIP_COVERAGE_ENFORCEMENT: "true"
          MAX_JOBS: 4
        run: |
          python3 ${{ github.workspace }}/scripts/cvc5/commit_fuzzer/prepare_commit_fuzzer_sancov.py \
            ${{ steps.get-commit.outputs.commit_hash }} \
            --coverage-json ../coverage_mapping.json \
            --compile-commands build \
            --output-matrix ../fuzzer_matrix.json \
            --output-changed-functions ../changed_functions.json \
            --max-jobs 4
          
          echo "changed_functions_file=changed_functions.json" >> $GITHUB_OUTPUT
          
          if [ -f "../fuzzer_matrix.json" ]; then
            TOTAL_TESTS=$(jq -r '.total_tests' ../fuzzer_matrix.json)
            echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
            
            jq -c --arg commit "${{ matrix.commit }}" '{
              "include": (.matrix.include | map({
                "commit": $commit,
                "fuzzer_job": .
              }))
            }' ../fuzzer_matrix.json > ../combined_matrix.json
          else
            echo "total_tests=0" >> $GITHUB_OUTPUT
            echo "{\"include\":[]}" > ../combined_matrix.json
          fi

      - name: Generate allowlists (sancov + PGO)
        id: generate-allowlists
        run: |
          if [ -f "changed_functions.json" ]; then
            python3 ${{ github.workspace }}/scripts/cvc5/partial_instrumentation/generate_allowlists.py \
              --input changed_functions.json \
              --output-sancov sancov_allowlist.txt \
              --output-pgo pgo_allowlist.txt
            
            if [ -f "sancov_allowlist.txt" ]; then
              echo "sancov_allowlist=sancov_allowlist.txt" >> $GITHUB_OUTPUT
              echo "âœ… Generated sancov allowlist with $(grep -c '^fun:' sancov_allowlist.txt || echo 0) functions"
            fi
            
            if [ -f "pgo_allowlist.txt" ]; then
              echo "pgo_allowlist=pgo_allowlist.txt" >> $GITHUB_OUTPUT
              echo "âœ… Generated PGO allowlist with $(grep -c '^fun:' pgo_allowlist.txt || echo 0) functions"
            fi
          else
            echo "âš ï¸ changed_functions.json not found"
          fi
      
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: changed-functions-${{ matrix.commit }}
          path: |
            changed_functions.json
            fuzzer_matrix.json
            sancov_allowlist.txt
            pgo_allowlist.txt
          if-no-files-found: ignore
      
      - name: Upload combined matrix
        uses: actions/upload-artifact@v4
        with:
          name: combined-matrix-${{ matrix.commit }}
          path: combined_matrix.json
          if-no-files-found: ignore

  collect-matrices:
    needs: [generate-matrix, prepare-commit-fuzzer]
    if: always()
    runs-on: ubuntu-latest
    outputs:
      fuzzing_matrix: ${{ steps.merge-matrices.outputs.fuzzing_matrix }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      
      - name: Download all combined matrices
        uses: actions/download-artifact@v4
        with:
          path: matrices
          pattern: combined-matrix-*
          merge-multiple: false
      
      - name: Merge all matrices
        id: merge-matrices
        run: |
          TOTAL_JOBS=$(python3 ${{ github.workspace }}/scripts/merge_fuzzing_matrices.py \
            fuzzing_matrix.json \
            "matrices/combined-matrix-*/combined_matrix.json" \
            --minimal-output fuzzing_matrix_minimal.json)
          
          MINIMAL_MATRIX=$(cat fuzzing_matrix_minimal.json)
          echo "fuzzing_matrix=$MINIMAL_MATRIX" >> $GITHUB_OUTPUT
          echo "total_jobs=$TOTAL_JOBS" >> $GITHUB_OUTPUT
      
      - name: Upload merged matrix
        uses: actions/upload-artifact@v4
        with:
          name: fuzzing-matrix-full
          path: fuzzing_matrix.json
          retention-days: 1

  fuzzing-jobs:
    needs: [generate-matrix, prepare-commit-fuzzer, collect-matrices]
    if: needs.collect-matrices.outputs.fuzzing_matrix != '' && needs.collect-matrices.outputs.fuzzing_matrix != '{"include":[]}'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.collect-matrices.outputs.fuzzing_matrix) }}
    timeout-minutes: 360  # 60 minutes fuzzing + build time with sancov
    
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      
      - name: Download full matrix data
        uses: actions/download-artifact@v4
        with:
          name: fuzzing-matrix-full
          path: .
      
      - name: Extract test list for this job
        id: extract-tests
        run: |
          python3 ${{ github.workspace }}/scripts/extract_matrix_tests.py \
            fuzzing_matrix.json \
            "${{ matrix.commit }}" \
            "${{ matrix.job_id }}" > tests_job_${{ matrix.job_id }}.json
          
          echo "tests_file=tests_job_${{ matrix.job_id }}.json" >> $GITHUB_OUTPUT
          TEST_COUNT=$(python3 -c "import json; print(len(json.load(open('tests_job_${{ matrix.job_id }}.json'))))")
          echo "âœ… Extracted $TEST_COUNT tests for job ${{ matrix.job_id }}"
      
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            python3 python3-pip unzip wget binutils \
            clang llvm lld libc++-dev libc++abi-dev cmake ninja-build
          sudo apt-get clean

      - name: Install fuzzing dependencies
        run: |
          pip install antlr4-python3-runtime==4.9.2 z3-solver psutil
          git clone https://github.com/testsmt/yinyang.git
          cd yinyang && pip install -e . && cd ..
          pip cache purge || true

      - name: Clone CVC5 repository
        run: |
          if [ ! -d "cvc5" ]; then
            git clone https://github.com/cvc5/cvc5.git cvc5
          fi

      - name: Checkout commit
        working-directory: cvc5
        run: |
          git fetch origin
          git checkout ${{ matrix.commit }}
          echo "Checked out commit: $(git rev-parse HEAD)"
      
      - name: Clean up git repositories
        run: rm -rf cvc5/.git yinyang/.git || true

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Download allowlists
        uses: actions/download-artifact@v4
        with:
          name: changed-functions-${{ matrix.commit }}
          path: .

      - name: Build CVC5 with sancov instrumentation
        run: |
          echo "=== Building CVC5 with sancov instrumentation ==="
          
          export WORKSPACE="${{ github.workspace }}"
          export COVERAGE_AGENT="${{ github.workspace }}/scripts/cvc5/partial_instrumentation/coverage_agent.cpp"
          
          # Setup allowlists (downloaded to current directory by previous step)
          SANCOV_ARG=""
          
          if [ -f "sancov_allowlist.txt" ]; then
            SANCOV_ARG="$(pwd)/sancov_allowlist.txt"
            echo "Using sancov allowlist: $(grep -c '^fun:' sancov_allowlist.txt || echo 0) functions"
          fi
          
          # Build with sancov instrumentation (only for changed functions)
          ${{ github.workspace }}/scripts/cvc5/partial_instrumentation/build_cvc5_instrumented.sh \
            "${{ matrix.commit }}" \
            "$SANCOV_ARG" \
            ""
          
          echo "âœ… Build complete"
          ls -la cvc5/build/bin/cvc5
      
      - name: Verify instrumentation
        id: verify-instrumentation
        run: |
          echo "=== Verifying instrumentation ==="
          SANCOV_SYM=$(nm cvc5/build/bin/cvc5 2>/dev/null | grep -c "__sanitizer_cov" || echo "0")
          echo "Sancov symbols: $SANCOV_SYM"
          
          # Count total instrumented edges from coverage agent debug output
          echo "=== Counting total instrumented edges ==="
          TOTAL_EDGES=$(COVERAGE_AGENT_DEBUG=1 cvc5/build/bin/cvc5 --version 2>&1 | grep -oP 'total_edges=\K\d+' || echo "0")
          echo "Total instrumented edges: $TOTAL_EDGES"
          echo "total_edges=${TOTAL_EDGES}" >> $GITHUB_OUTPUT
          
          echo "âœ… Binary works"
      
      - name: Verify solvers
        run: |
          z3 --version
          cvc5/build/bin/cvc5 --version

      - name: Run coverage-guided fuzzing with recipe recording
        working-directory: cvc5
        env:
          PYTHONUNBUFFERED: "1"
        run: |
          FUZZING_DURATION="${{ inputs.fuzzing_duration_minutes || 60 }}"
          TOTAL_EDGES="${{ steps.verify-instrumentation.outputs.total_edges }}"
          
          mkdir -p output profraw bugs
          
          echo "=== Starting coverage-guided fuzzing ==="
          echo "Duration: ${FUZZING_DURATION} minutes"
          echo "Workers: 4"
          echo "Total instrumented edges: ~${TOTAL_EDGES}"
          
          # Use setsid to isolate fuzzer from shell signals (fixes inline mode SIGINT issue)
          setsid python3 ${{ github.workspace }}/scripts/cvc5/partial_instrumentation/coverage_guided_fuzzer.py \
            --tests-file ../${{ steps.extract-tests.outputs.tests_file }} \
            --job-id '${{ matrix.job_id }}' \
            --tests-root 'test/regress/cli' \
            --fuzzing-duration-minutes ${FUZZING_DURATION} \
            --seed 42 \
            --inline \
            --total-edges ${TOTAL_EDGES} \
            --cvc5-path ./build/bin/cvc5 \
            --workers 4 \
            --bugs-folder ./bugs \
            --output-dir ./output \
            --profraw-dir ./profraw \
            --recipe-output ../recipes_${{ matrix.commit }}_job_${{ matrix.job_id }} || true
          
          echo "=== Fuzzing complete ==="
          cat ./output/coverage_stats.json || echo "No coverage stats"
      
      - name: Extract function counts from PGO data
        if: always()
        working-directory: cvc5
        run: |
          echo "=== Extracting function counts ==="
          
          # DEBUG: List all profraw files before any merge
          echo "=== DEBUG: Profraw files in ./profraw ==="
          ls -la ./profraw/*.profraw 2>/dev/null || echo "No profraw files in ./profraw"
          PROFRAW_COUNT=$(find ./profraw -name "*.profraw" -type f 2>/dev/null | wc -l)
          echo "Total profraw files: $PROFRAW_COUNT"
          
          # DEBUG: Check accumulated.profdata from periodic merges
          if [ -f "./output/accumulated.profdata" ]; then
            echo "=== DEBUG: accumulated.profdata exists (from periodic merges) ==="
            ls -la ./output/accumulated.profdata
          fi
          
          # DEBUG: Check profraw file sizes (showing first 10 files)
          echo "=== DEBUG: Checking profraw file sizes ==="
          COUNT=0
          if ls ./profraw/*.profraw 1>/dev/null 2>&1; then
            for f in ./profraw/*.profraw; do
              if [ -f "$f" ] && [ $COUNT -lt 10 ]; then
                FILE_SIZE=$(stat -c%s "$f" 2>/dev/null || stat -f%z "$f" 2>/dev/null || echo "unknown")
                echo "  $f: size=${FILE_SIZE}B"
                COUNT=$((COUNT + 1))
              fi
            done
            if [ $COUNT -eq 10 ]; then
              echo "  ... and more files"
            fi
          else
            echo "  No profraw files found"
          fi
          
          # Check if fuzzer already created merged.profdata
          if [ -f "./output/merged.profdata" ]; then
            echo "âœ… Using existing merged.profdata from fuzzer"
            # DEBUG: Show what's in the merged profdata
            echo "=== DEBUG: Contents of merged.profdata ==="
            llvm-profdata show ./output/merged.profdata 2>/dev/null | head -50 || echo "Could not show profdata"
          else
            # Fallback: merge profraw files if they exist
            echo "No merged.profdata from fuzzer, attempting manual merge..."
            
            if [ "$PROFRAW_COUNT" -gt 0 ]; then
              echo "Merging $PROFRAW_COUNT profraw files..."
              llvm-profdata merge -sparse -o ./output/merged.profdata ./profraw/*.profraw || true
            fi
          fi
          
          # Extract function counts if we have profdata
          if [ -f "./output/merged.profdata" ]; then
            echo "âœ… Merged profdata available"
            
            # Extract function counts
            python3 ${{ github.workspace }}/scripts/cvc5/partial_instrumentation/extract_function_counts.py \
              ./build/bin/cvc5 \
              --profdata ./output/merged.profdata \
              --output ../function_counts_${{ matrix.commit }}_${{ matrix.job_id }}.json || true
            
            # Convert to baseline-compatible format
            if [ -f "../function_counts_${{ matrix.commit }}_${{ matrix.job_id }}.json" ]; then
              python3 ${{ github.workspace }}/scripts/cvc5/partial_instrumentation/convert_function_counts.py \
                ../function_counts_${{ matrix.commit }}_${{ matrix.job_id }}.json \
                --commit '${{ matrix.commit }}' \
                --job-id '${{ matrix.job_id }}'
            fi
          else
            echo "âš ï¸ No profdata available for function count extraction"
          fi
          
          # Also save coverage stats
          if [ -f "./output/coverage_stats.json" ]; then
            cp ./output/coverage_stats.json ../coverage_stats_${{ matrix.commit }}_${{ matrix.job_id }}.json
          fi
      
      - name: Upload fuzzing results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fuzzing-results-${{ matrix.commit }}-job-${{ matrix.job_id }}
          path: |
            function_counts_${{ matrix.commit }}_${{ matrix.job_id }}.json
            coverage_stats_${{ matrix.commit }}_${{ matrix.job_id }}.json
            cvc5/bugs/**/*.smt2
          if-no-files-found: ignore
      
      - name: Upload recipes artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: variant2-recipes-commit-${{ matrix.commit }}-job-${{ matrix.job_id }}
          path: recipes_${{ matrix.commit }}_job_${{ matrix.job_id }}.jsonl
          if-no-files-found: ignore

  merge-and-upload-recipes:
    needs: [generate-matrix, prepare-commit-fuzzer, fuzzing-jobs]
    if: always() && needs.prepare-commit-fuzzer.result == 'success'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-matrix.outputs.commit_matrix) }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      
      - name: Download all recipe artifacts for commit
        uses: actions/download-artifact@v4
        with:
          path: recipes-artifacts
          pattern: variant2-recipes-commit-${{ matrix.commit }}-job-*
          merge-multiple: false
      
      - name: Download changed functions
        uses: actions/download-artifact@v4
        with:
          name: changed-functions-${{ matrix.commit }}
          path: .
      
      - name: Merge recipes from all jobs
        run: |
          RECIPE_FILES=$(find recipes-artifacts -name "recipes_${{ matrix.commit }}_job_*.jsonl" -type f | sort)
          
          if [ -z "$RECIPE_FILES" ]; then
            echo "âš ï¸ No recipe files found for commit ${{ matrix.commit }}"
            exit 0
          fi
          
          FILE_COUNT=$(echo "$RECIPE_FILES" | wc -l)
          echo "Found $FILE_COUNT recipe files"
          
          # Merge all recipe files into one
          cat $RECIPE_FILES > merged_recipes_${{ matrix.commit }}.jsonl
          
          TOTAL_RECIPES=$(wc -l < merged_recipes_${{ matrix.commit }}.jsonl)
          echo "âœ… Merged $TOTAL_RECIPES recipes from $FILE_COUNT job files"
          
          # Show sample of merged recipes for debugging
          echo ""
          echo "=== First 10 recipes (sample) ==="
          head -10 merged_recipes_${{ matrix.commit }}.jsonl
          echo ""
          echo "=== Last 5 recipes ==="
          tail -5 merged_recipes_${{ matrix.commit }}.jsonl
      
      - name: Configure AWS credentials
        if: ${{ !inputs.dry_run }}
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Get full commit hash
        id: get-commit-merge
        run: |
          echo "commit_hash=${{ matrix.commit }}" >> $GITHUB_OUTPUT
      
      - name: Upload recipes to S3
        if: always() && !inputs.dry_run
        run: |
          COMMIT_HASH="${{ steps.get-commit-merge.outputs.commit_hash }}"
          S3_KEY="evaluation/rq2/cvc5/fuzzing-recipes/variant2/recipes-${COMMIT_HASH}.jsonl.gz"
          
          if [ ! -f "merged_recipes_${{ matrix.commit }}.jsonl" ]; then
            echo "âš ï¸ Merged recipes file not found"
            exit 0
          fi
          
          gzip -c "merged_recipes_${{ matrix.commit }}.jsonl" > recipes_${COMMIT_HASH}.jsonl.gz
          
          aws s3api put-object \
            --bucket ${{ secrets.AWS_S3_BUCKET }} \
            --key "$S3_KEY" \
            --body recipes_${COMMIT_HASH}.jsonl.gz
          
          echo "âœ… Uploaded variant2 recipes to S3: $S3_KEY"
      
      - name: Upload changed functions to S3
        if: always() && !inputs.dry_run
        run: |
          COMMIT_HASH="${{ steps.get-commit-merge.outputs.commit_hash }}"
          S3_KEY="evaluation/rq2/cvc5/changed-functions/changed_functions-${COMMIT_HASH}.json.gz"
          
          if [ ! -f "changed_functions.json" ]; then
            echo "âš ï¸ changed_functions.json not found"
            exit 0
          fi
          
          # Show changed functions content for debugging
          echo "=== Changed Functions Content ==="
          cat changed_functions.json | python3 -m json.tool
          
          gzip -c "changed_functions.json" > changed_functions_${COMMIT_HASH}.json.gz
          
          aws s3api put-object \
            --bucket ${{ secrets.AWS_S3_BUCKET }} \
            --key "$S3_KEY" \
            --body changed_functions_${COMMIT_HASH}.json.gz
          
          echo "âœ… Uploaded changed functions to S3: $S3_KEY"
      
      - name: Dry run - Skip S3 upload
        if: always() && inputs.dry_run
        run: |
          COMMIT_HASH="${{ steps.get-commit-merge.outputs.commit_hash }}"
          
          if [ -f "merged_recipes_${{ matrix.commit }}.jsonl" ]; then
            RECIPE_COUNT=$(wc -l < "merged_recipes_${{ matrix.commit }}.jsonl")
            echo "ðŸ” DRY RUN: Would upload $RECIPE_COUNT recipes to S3"
          else
            echo "âš ï¸ Merged recipes file not found"
          fi
