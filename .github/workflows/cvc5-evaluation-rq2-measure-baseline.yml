name: CVC5 RQ2 Measurement - Baseline

on:
  workflow_dispatch:
    inputs:
      debug_commit_hash:
        description: 'Debug: Specific commit hash to measure. If provided, only this commit will be measured.'
        required: false
        type: string
      dry_run:
        description: 'Dry run: Skip S3 uploads (default: false)'
        required: false
        type: boolean
        default: false

jobs:
  # ============================================================
  # PHASE 1: Generate commit matrix from available recipes
  # ============================================================
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      commit_matrix: ${{ steps.generate-matrix.outputs.commit_matrix }}
      total_commits: ${{ steps.generate-matrix.outputs.total_commits }}
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v5
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: pip install boto3
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Generate commit matrix from recipes
        id: generate-matrix
        env:
          AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          if [ -n "${{ inputs.debug_commit_hash }}" ]; then
            echo "ðŸ” Debug mode: Using specific commit ${{ inputs.debug_commit_hash }}"
            DEBUG_COMMIT="${{ inputs.debug_commit_hash }}"
            COMMIT_MATRIX=$(python3 -c "import json; print(json.dumps({'include': [{'commit': '$DEBUG_COMMIT'}]}, separators=(',', ':')))")
            TOTAL_COMMITS=1
          else
            # List commits that have baseline recipes
            prefix="evaluation/rq2/cvc5/fuzzing-recipes/baseline/"
            commits=$(aws s3 ls s3://${{ secrets.AWS_S3_BUCKET }}/$prefix --recursive | \
              grep "recipes-" | \
              sed 's/.*recipes-\(.*\)\.jsonl\.gz/\1/' | \
              sort -u)
            
            commit_count=$(echo "$commits" | grep -c . || echo 0)
            echo "âœ… Found $commit_count commits with baseline recipes"
            
            # Generate matrix
            echo "[]" > /tmp/matrix_entries.json
            for commit in $commits; do
              jq --arg commit "$commit" '. + [{"commit": $commit}]' /tmp/matrix_entries.json > /tmp/matrix_entries_new.json
              mv /tmp/matrix_entries_new.json /tmp/matrix_entries.json
            done
            
            COMMIT_MATRIX=$(jq -c '{include: .}' /tmp/matrix_entries.json)
            TOTAL_COMMITS=$commit_count
          fi
          
          echo "commit_matrix=$COMMIT_MATRIX" >> $GITHUB_OUTPUT
          echo "total_commits=$TOTAL_COMMITS" >> $GITHUB_OUTPUT

  # ============================================================
  # PHASE 2: Prepare measurement - split recipes into 4 jobs per commit
  # ============================================================
  prepare-measurement:
    needs: generate-matrix
    if: needs.generate-matrix.outputs.total_commits != '' && needs.generate-matrix.outputs.total_commits != '0'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-matrix.outputs.commit_matrix) }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Download recipes from S3
        run: |
          COMMIT_HASH="${{ matrix.commit }}"
          S3_KEY="evaluation/rq2/cvc5/fuzzing-recipes/baseline/recipes-${COMMIT_HASH}.jsonl.gz"
          
          aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/$S3_KEY recipes.jsonl.gz
          gunzip recipes.jsonl.gz
          
          RECIPE_COUNT=$(wc -l < recipes.jsonl)
          echo "âœ… Downloaded $RECIPE_COUNT recipes for baseline measurement"
      
      - name: Split recipes into 4 jobs (by seed boundaries)
        run: |
          # Split by seed boundaries to keep all iterations of a seed in the same job
          python3 scripts/rq2/split_recipes_for_measurement.py \
            recipes.jsonl \
            --num-jobs 4 \
            --output measurement_matrix.json
          
          echo "=== Measurement Matrix ==="
          cat measurement_matrix.json | python3 -m json.tool
          
          # Create combined matrix with commit
          jq -c --arg commit "${{ matrix.commit }}" '{
            "include": (.matrix.include | map({
              "commit": $commit,
              "job_id": .job_id,
              "recipe_count": .recipe_count,
              "seed_count": .seed_count,
              "seeds_file": .seeds_file
            }))
          }' measurement_matrix.json > combined_matrix.json
          
          echo "=== Combined Matrix ==="
          cat combined_matrix.json | python3 -m json.tool
          
          # Show generated seeds files
          echo ""
          echo "=== Seeds files generated ==="
          for f in seeds_job_*.json; do
            echo "--- $f ---"
            cat "$f" | python3 -m json.tool
          done
      
      - name: Upload combined matrix, seeds files, and recipes
        uses: actions/upload-artifact@v4
        with:
          name: baseline-measurement-matrix-${{ matrix.commit }}
          path: |
            combined_matrix.json
            seeds_job_*.json
            recipes.jsonl
          if-no-files-found: error

  # ============================================================
  # PHASE 3: Collect all matrices into one
  # ============================================================
  collect-matrices:
    needs: [generate-matrix, prepare-measurement]
    if: always() && needs.prepare-measurement.result == 'success'
    runs-on: ubuntu-latest
    outputs:
      measurement_matrix: ${{ steps.merge-matrices.outputs.measurement_matrix }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      
      - name: Download all combined matrices
        uses: actions/download-artifact@v4
        with:
          path: matrices
          pattern: baseline-measurement-matrix-*
          merge-multiple: false
      
      - name: Merge all matrices
        id: merge-matrices
        run: |
          # Use Python script for reliable matrix merging
          TOTAL_JOBS=$(python3 scripts/merge_fuzzing_matrices.py \
            measurement_matrix.json \
            "matrices/baseline-measurement-matrix-*/combined_matrix.json" \
            --minimal-output measurement_matrix_minimal.json)
          
          MINIMAL_MATRIX=$(cat measurement_matrix_minimal.json)
          echo "measurement_matrix=$MINIMAL_MATRIX" >> $GITHUB_OUTPUT
          echo "total_jobs=$TOTAL_JOBS" >> $GITHUB_OUTPUT
          echo "âœ… Merged $TOTAL_JOBS measurement jobs"
      
      - name: Upload merged matrix
        uses: actions/upload-artifact@v4
        with:
          name: baseline-measurement-matrix-full
          path: measurement_matrix.json
          retention-days: 1

  # ============================================================
  # PHASE 4: Run measurement jobs (4 per commit, in parallel)
  # ============================================================
  measurement-jobs:
    needs: [generate-matrix, prepare-measurement, collect-matrices]
    if: needs.collect-matrices.outputs.measurement_matrix != '' && needs.collect-matrices.outputs.measurement_matrix != '{"include":[]}'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.collect-matrices.outputs.measurement_matrix) }}
    timeout-minutes: 360
    
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      
      - name: Download matrix and seeds files for this commit
        uses: actions/download-artifact@v4
        with:
          name: baseline-measurement-matrix-${{ matrix.commit }}
          path: matrix-data
      
      - name: Extract job parameters
        id: job-params
        run: |
          # Get seeds file for this job
          SEEDS_FILE="matrix-data/seeds_job_${{ matrix.job_id }}.json"
          
          if [ ! -f "$SEEDS_FILE" ]; then
            echo "âŒ Seeds file not found: $SEEDS_FILE"
            ls -la matrix-data/
            exit 1
          fi
          
          # Extract info
          SEED_COUNT=$(jq '.seeds | length' "$SEEDS_FILE")
          
          echo "seeds_file=$SEEDS_FILE" >> $GITHUB_OUTPUT
          echo "seed_count=$SEED_COUNT" >> $GITHUB_OUTPUT
          
          echo "ðŸ“Š Job ${{ matrix.job_id }}: $SEED_COUNT seeds"
          echo ""
          echo "=== Seeds for this job ==="
          cat "$SEEDS_FILE" | python3 -m json.tool
      
      - name: Install GCC 14 (for gcov)
        run: |
          sudo apt-get update
          # gcov-14 is included with gcc-14 (not a separate package)
          sudo apt-get install -y gcc-14 g++-14
          sudo update-alternatives --install /usr/bin/gcov gcov /usr/bin/gcov-14 60
          pip install fastcov
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          pip install antlr4-python3-runtime==4.9.2
          pip install z3-solver
          pip install psutil
          git clone https://github.com/testsmt/yinyang.git
          cd yinyang && pip install -e . && cd ..
      
      - name: Clone CVC5 repository
        run: |
          git clone https://github.com/cvc5/cvc5.git cvc5
      
      - name: Checkout commit
        working-directory: cvc5
        run: |
          git fetch origin
          git checkout ${{ matrix.commit }}
          echo "Checked out commit: $(git rev-parse HEAD)"
      
      - name: Get full commit hash
        id: get-commit
        working-directory: cvc5
        run: |
          FULL_HASH=$(git rev-parse HEAD)
          echo "commit_hash=$FULL_HASH" >> $GITHUB_OUTPUT
      
      - name: Clean up git repositories
        run: rm -rf cvc5/.git yinyang/.git || true
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Use recipes from artifact
        run: |
          # Use recipes.jsonl from the same artifact as seeds files (ensures consistency)
          cp matrix-data/recipes.jsonl recipes.jsonl
          
          RECIPE_COUNT=$(wc -l < recipes.jsonl)
          echo "âœ… Using $RECIPE_COUNT recipes from artifact"
          
          # Show sample
          echo ""
          echo "=== First 5 recipes (sample) ==="
          head -5 recipes.jsonl | python3 -m json.tool --no-ensure-ascii 2>/dev/null || head -5 recipes.jsonl
      
      - name: Download gcov binary from S3
        run: |
          COMMIT_HASH="${{ steps.get-commit.outputs.commit_hash }}"
          S3_KEY="evaluation/rq2/cvc5/builds/coverage/${COMMIT_HASH}.tar.gz"
          
          mkdir -p artifacts
          aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/$S3_KEY artifacts/artifacts.tar.gz
          echo "âœ… Downloaded gcov binary for $COMMIT_HASH"
      
      - name: Extract gcov binary
        run: |
          ./scripts/cvc5/extract_build_artifacts.sh artifacts/artifacts.tar.gz cvc5/build true
          echo "âœ… Extracted build artifacts"
          
          # Verify gcno files exist
          GCNO_COUNT=$(find cvc5/build -name "*.gcno" | wc -l)
          echo "Found $GCNO_COUNT .gcno files"
      
      - name: Clone CVC5 repository (for test files)
        run: |
          COMMIT_HASH="${{ steps.get-commit.outputs.commit_hash }}"
          
          # Clone CVC5 to get the test files that recipes reference
          if [ ! -d "cvc5/.git" ]; then
            git clone --depth 1 https://github.com/cvc5/cvc5.git cvc5-src
            cd cvc5-src
            git fetch --depth 1 origin $COMMIT_HASH
            git checkout $COMMIT_HASH
            cd ..
            # Move test directory to cvc5/
            cp -r cvc5-src/test cvc5/test
            rm -rf cvc5-src
          fi
          
          # Verify test files exist
          TEST_COUNT=$(find cvc5/test/regress -name "*.smt2" | wc -l)
          echo "âœ… Found $TEST_COUNT test files in cvc5/test/regress"
      
      - name: Download changed functions from S3
        run: |
          COMMIT_HASH="${{ steps.get-commit.outputs.commit_hash }}"
          S3_KEY="evaluation/rq2/cvc5/changed-functions/changed_functions-${COMMIT_HASH}.json.gz"
          
          aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/$S3_KEY changed_functions.json.gz
          gunzip changed_functions.json.gz
          
          FUNC_COUNT=$(jq '.changed_functions | length' changed_functions.json 2>/dev/null || echo "unknown")
          echo "âœ… Downloaded changed functions: $FUNC_COUNT functions"
          
          # Show changed functions content
          echo ""
          echo "=== Changed Functions ==="
          cat changed_functions.json | python3 -m json.tool
      
      - name: Verify solver binary
        run: |
          cvc5/build/bin/cvc5 --version
      
      - name: Run recipe replay for measurement
        working-directory: cvc5
        run: |
          SEEDS_FILE="${{ github.workspace }}/${{ steps.job-params.outputs.seeds_file }}"
          
          echo "=== Starting recipe replay for job ${{ matrix.job_id }} ==="
          echo "    Seeds file: $SEEDS_FILE"
          echo "    Seeds count: ${{ steps.job-params.outputs.seed_count }}"
          
          # Run from cvc5/ directory so seed paths in recipes resolve correctly
          python3 ${{ github.workspace }}/scripts/rq2/replay_recipes.py \
            ../recipes.jsonl \
            --solver ./build/bin/cvc5 \
            --build-dir ./build \
            --changed-functions ../changed_functions.json \
            --output ../measurement_result_${{ matrix.commit }}_job${{ matrix.job_id }}.json \
            --gcov gcov-14 \
            --timeout 120 \
            --num-workers 4 \
            --seeds-file "$SEEDS_FILE" \
            --legacy
          
          echo "=== Measurement complete for job ${{ matrix.job_id }} ==="
      
      - name: Show job measurement results
        if: always()
        run: |
          RESULT_FILE="measurement_result_${{ matrix.commit }}_job${{ matrix.job_id }}.json"
          if [ -f "$RESULT_FILE" ]; then
            echo "=== MEASUREMENT RESULTS (Job ${{ matrix.job_id }}) ==="
            cat "$RESULT_FILE" | python3 -m json.tool
          else
            echo "âš ï¸ Measurement results file not found"
          fi
      
      - name: Upload job result artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: baseline-measurement-result-${{ matrix.commit }}-job${{ matrix.job_id }}
          path: measurement_result_${{ matrix.commit }}_job${{ matrix.job_id }}.json
          if-no-files-found: ignore

  # ============================================================
  # PHASE 5: Merge results and upload to S3
  # ============================================================
  merge-and-upload-results:
    needs: [generate-matrix, prepare-measurement, measurement-jobs]
    if: always() && needs.prepare-measurement.result == 'success'
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      matrix: ${{ fromJson(needs.generate-matrix.outputs.commit_matrix) }}
    
    steps:
      - name: Checkout
        uses: actions/checkout@v5
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Download job result artifacts
        uses: actions/download-artifact@v4
        with:
          path: results-artifacts
          pattern: baseline-measurement-result-${{ matrix.commit }}-job*
          merge-multiple: false
      
      - name: List downloaded artifacts
        run: |
          echo "=== Downloaded artifacts ==="
          find results-artifacts -type f -name "*.json" | sort
      
      - name: Merge job results
        run: |
          RESULT_FILES=$(find results-artifacts -name "measurement_result_*.json" | sort)
          FILE_COUNT=$(echo "$RESULT_FILES" | grep -c . || echo 0)
          
          echo "Found $FILE_COUNT result files to merge"
          
          if [ "$FILE_COUNT" -eq 0 ]; then
            echo "âš ï¸ No result files found"
            exit 0
          fi
          
          python3 scripts/rq2/merge_measurement_results.py \
            merged_measurement_${{ matrix.commit }}.json \
            $RESULT_FILES
          
          echo ""
          echo "=== MERGED MEASUREMENT RESULTS ==="
          cat merged_measurement_${{ matrix.commit }}.json | python3 -m json.tool
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Upload merged results to S3
        if: always() && !inputs.dry_run
        run: |
          COMMIT_HASH="${{ matrix.commit }}"
          S3_KEY="evaluation/rq2/cvc5/measurement-results/baseline/measurement-${COMMIT_HASH}.json.gz"
          
          if [ ! -f "merged_measurement_${{ matrix.commit }}.json" ]; then
            echo "âš ï¸ Merged measurement results file not found"
            exit 0
          fi
          
          gzip -c "merged_measurement_${{ matrix.commit }}.json" > measurement_${COMMIT_HASH}.json.gz
          
          aws s3api put-object \
            --bucket ${{ secrets.AWS_S3_BUCKET }} \
            --key "$S3_KEY" \
            --body measurement_${COMMIT_HASH}.json.gz
          
          echo "âœ… Uploaded baseline measurement results to S3: $S3_KEY"
