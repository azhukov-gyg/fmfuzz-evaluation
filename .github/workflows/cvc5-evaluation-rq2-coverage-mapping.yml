name: CVC5 RQ2 Coverage Mapping (Variant 1)

on:
  workflow_dispatch:
    inputs:
      max_commits:
        description: 'Maximum number of commits to process (for testing, leave empty for all)'
        required: false
        type: string

jobs:
  generate-matrix:
    runs-on: ubuntu-latest
    outputs:
      matrix: ${{ steps.generate-matrix.outputs.matrix }}
      commit_matrix: ${{ steps.generate-matrix.outputs.commit_matrix }}
      total_commits: ${{ steps.generate-matrix.outputs.total_commits }}
      chunks_per_commit: ${{ steps.generate-matrix.outputs.chunks_per_commit }}
    
    steps:
      - name: Checkout repository and submodules
        uses: actions/checkout@v5
        with:
          submodules: recursive
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install dependencies
        run: |
          pip install boto3 psutil
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Checkout CVC5 repository
        run: |
          if [ -d "cvc5" ]; then
            cd cvc5
            git fetch origin
          else
            git clone https://github.com/cvc5/cvc5.git cvc5
            cd cvc5
          fi
      
      - name: Configure CMake (for ctest discovery)
        run: |
          cd cvc5
          ./configure.sh debug --auto-download
      
      - name: Generate combined matrix
        id: generate-matrix
        env:
          AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
          AWS_REGION: ${{ secrets.AWS_REGION }}
        run: |
          MAX_COMMITS="${{ inputs.max_commits }}"
          if [ -n "$MAX_COMMITS" ] && [ "$MAX_COMMITS" != "" ]; then
            RESULT=$(python3 scripts/rq2/generate_coverage_matrix.py cvc5 "$MAX_COMMITS")
          else
            RESULT=$(python3 scripts/rq2/generate_coverage_matrix.py cvc5)
          fi
          
          MATRIX=$(echo "$RESULT" | python3 -c "import sys, json; data=json.load(sys.stdin); print(json.dumps({'include': data['include']}, separators=(',', ':')))")
          TOTAL_COMMITS=$(echo "$RESULT" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data['total_commits'])")
          CHUNKS_PER_COMMIT=$(echo "$RESULT" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data['chunks_per_commit'])")
          COMMIT_MATRIX=$(echo "$RESULT" | python3 -c "import sys, json; data=json.load(sys.stdin); commits = sorted(set(item['commit'] for item in data['include'])); print(json.dumps({'include': [{'commit': c} for c in commits]}, separators=(',', ':')))")
          
          echo "matrix=$MATRIX" >> $GITHUB_OUTPUT
          echo "commit_matrix=$COMMIT_MATRIX" >> $GITHUB_OUTPUT
          echo "total_commits=$TOTAL_COMMITS" >> $GITHUB_OUTPUT
          echo "chunks_per_commit=$CHUNKS_PER_COMMIT" >> $GITHUB_OUTPUT
          
          echo "✅ Generated matrix: $TOTAL_COMMITS commits × $CHUNKS_PER_COMMIT chunks"

  coverage-analysis:
    needs: generate-matrix
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 20
      matrix: ${{ fromJson(needs.generate-matrix.outputs.matrix) }}
    timeout-minutes: 360
    
    steps:
      - name: Checkout repository and submodules
        uses: actions/checkout@v5
        with:
          submodules: recursive
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Download coverage binary
        run: |
          COMMIT_HASH="${{ matrix.commit }}"
          S3_KEY="evaluation/rq2/cvc5/builds/coverage/${COMMIT_HASH}.tar.gz"
          
          mkdir -p artifacts
          aws s3 cp s3://${{ secrets.AWS_S3_BUCKET }}/$S3_KEY artifacts/artifacts.tar.gz
          echo "✅ Downloaded coverage binary for $COMMIT_HASH"
      
      - name: Checkout exact CVC5 commit (for source files and CTest discovery)
        uses: actions/checkout@v5
        with:
          repository: cvc5/cvc5
          ref: ${{ matrix.commit }}
          path: cvc5
          fetch-depth: 0
      
      - name: Extract coverage binary (preserving source files)
        run: |
          mkdir -p cvc5/build
          ./scripts/cvc5/extract_build_artifacts.sh artifacts/artifacts.tar.gz cvc5/build true
      
      - name: Configure CMake in build directory (for CTest discovery)
        run: |
          cd cvc5/build
          cmake -DENABLE_TESTING=ON -DBUILD_TESTING=ON .. || echo "⚠️ CMake configuration failed, but continuing..."
      
      - name: Install system dependencies for coverage
        run: |
          sudo apt-get update
          sudo apt-get install -y gcc g++ binutils cmake
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      
      - name: Install Python dependencies
        run: |
          pip install psutil fastcov
      
      - name: Run test and diagnose coverage collection
        working-directory: cvc5/build
        env:
          TEST_TIMEOUT: 120
        run: |
          echo "=== Step 1: Check workspace structure ==="
          echo "Current directory: $(pwd)"
          echo "Workspace root: $GITHUB_WORKSPACE"
          echo ""
          
          echo "=== Step 2: Check .gcno files ==="
          SAMPLE_GCNO=$(find . -name "*.gcno" -type f | head -1)
          if [ -n "$SAMPLE_GCNO" ]; then
            echo "Sample .gcno: $SAMPLE_GCNO"
            ABSOLUTE_PATH=$(strings "$SAMPLE_GCNO" | grep -E "^/.*\.cpp$" | head -1)
            echo "Path in .gcno: $ABSOLUTE_PATH"
            if [ -f "$ABSOLUTE_PATH" ]; then
              echo "✓ Source file exists at absolute path"
            else
              echo "✗ Source file does NOT exist at absolute path"
            fi
          fi
          echo ""
          
          echo "=== Step 3: Clear existing .gcda files ==="
          find . -name "*.gcda" -type f -delete
          echo "Cleared all .gcda files"
          echo ""
          
          echo "=== Step 4: Run a test to generate coverage ==="
          ctest -I 1,1 -j1 --output-on-failure 2>&1
          TEST_EXIT=$?
          echo "Test exit code: $TEST_EXIT"
          echo ""
          
          echo "=== Step 5: Check what .gcda files were created ==="
          GCDA_COUNT=$(find . -name "*.gcda" -type f 2>/dev/null | wc -l)
          echo "Found $GCDA_COUNT .gcda files"
          if [ "$GCDA_COUNT" -gt 0 ]; then
            echo "Sample .gcda files:"
            find . -name "*.gcda" -type f | head -5
          fi
          echo ""
          
          echo "=== Step 6: Check compiler/gcov versions ==="
          echo "GCC version used for gcov:"
          gcc --version
          echo ""
          echo "Gcov version:"
          gcov --version
          echo ""
          echo "Checking what compiler was used to build (from .gcno file):"
          if [ -n "$SAMPLE_GCNO" ]; then
            echo "GCC version string in .gcno:"
            strings "$SAMPLE_GCNO" | grep -i "gcc\|clang" | head -5
            echo ""
            echo "Version info in .gcno:"
            strings "$SAMPLE_GCNO" | grep -E "version|Version|VERSION" | head -10
          fi
          echo ""
          
          echo "=== Step 7: Check LLVM/Clang version (if used for build) ==="
          if command -v clang >/dev/null 2>&1; then
            echo "Clang version:"
            clang --version
          fi
          echo ""
          
          echo "=== Step 8: Run gcov manually on a sample file ==="
          if [ -n "$SAMPLE_GCNO" ]; then
            SAMPLE_GCDA="${SAMPLE_GCNO%.gcno}.gcda"
            if [ -f "$SAMPLE_GCDA" ]; then
              echo "Running gcov on: $SAMPLE_GCDA"
              echo "Working directory: $(pwd)"
              echo "Full gcov output:"
              gcov "$SAMPLE_GCDA" 2>&1
              GCOV_EXIT=$?
              echo "gcov exit code: $GCOV_EXIT"
              echo ""
              
              echo "=== Step 9: Check what files gcov created ==="
              GCOV_FILE="${SAMPLE_GCDA%.gcda}.gcov"
              if [ -f "$GCOV_FILE" ]; then
                echo "✓ .gcov file created: $GCOV_FILE"
                echo "File size: $(wc -l < "$GCOV_FILE") lines"
                echo "First 30 lines:"
                head -30 "$GCOV_FILE"
              else
                echo "✗ No .gcov file created"
                echo "Files in directory $(dirname "$SAMPLE_GCDA"):"
                ls -la "$(dirname "$SAMPLE_GCDA")" | grep -E "\.gcov|\.gcda|\.gcno"
                echo ""
                echo "Checking if .gcov file was created elsewhere:"
                find . -name "*.gcov" -type f 2>/dev/null | head -5
              fi
            else
              echo "No corresponding .gcda file found for $SAMPLE_GCNO"
            fi
          fi
          echo ""
          
          echo "=== Step 8: Test fastcov ==="
          fastcov --gcov gcov --search-directory . --output test_fastcov.json --exclude "/usr/include/*" --exclude "*/deps/*" --jobs 1 2>&1
          if [ -f "test_fastcov.json" ]; then
            echo "fastcov output file created"
            echo "File size: $(wc -l < test_fastcov.json) lines"
            echo "Content:"
            cat test_fastcov.json
          else
            echo "✗ fastcov output file NOT created"
          fi
      
      - name: Run coverage analysis
        working-directory: cvc5/build
        env:
          TEST_TIMEOUT: 120
        run: |
          python3 ../../fmfuzz-dev/scripts/cvc5/coverage/coverage_mapper.py \
            --build-dir . \
            --start-index ${{ matrix.chunk.start_index }} \
            --end-index ${{ matrix.chunk.end_index }}
      
      - name: Upload coverage mapping chunk
        uses: actions/upload-artifact@v4
        with:
          name: coverage-mapping-${{ matrix.commit }}-${{ matrix.chunk.job_name }}
          path: cvc5/build/coverage_mapping_${{ matrix.chunk.start_index }}_${{ matrix.chunk.end_index }}.json
          retention-days: 1

  join-mappings:
    needs: [generate-matrix, coverage-analysis]
    runs-on: ubuntu-latest
    strategy:
      fail-fast: false
      max-parallel: 20
      matrix: ${{ fromJson(needs.generate-matrix.outputs.commit_matrix) }}
    timeout-minutes: 60
    
    steps:
      - name: Checkout repository and submodules
        uses: actions/checkout@v5
        with:
          submodules: recursive
      
      - name: Download all coverage mapping chunks for commit
        uses: actions/download-artifact@v4
        with:
          pattern: coverage-mapping-${{ matrix.commit }}-*
          path: coverage-mappings
      
      - name: Join coverage mappings
        run: |
          python3 fmfuzz-dev/scripts/cvc5/coverage/join_coverage_mappings.py
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v5.1.0
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      
      - name: Upload coverage mapping to S3
        run: |
          COMMIT_HASH="${{ matrix.commit }}"
          S3_KEY="evaluation/rq2/cvc5/coverage-mappings/variant1/coverage_mapping-${COMMIT_HASH}.json.gz"
          
          if [ ! -f "coverage_mapping.json.gz" ]; then
            echo "❌ Error: coverage_mapping.json.gz not found"
            exit 1
          fi
          
          aws s3api put-object \
            --bucket ${{ secrets.AWS_S3_BUCKET }} \
            --key "$S3_KEY" \
            --body coverage_mapping.json.gz
          
          echo "✅ Uploaded coverage mapping to S3: $S3_KEY"

